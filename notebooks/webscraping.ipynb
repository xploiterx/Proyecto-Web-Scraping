{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "NoneType = type(None)\n",
    "import os\n",
    "import socket\n",
    "import hashlib\n",
    "import string\n",
    "\n",
    "import time\n",
    "from osgeo import ogr\n",
    "import geopandas as gpd\n",
    "from pyspark.sql import SparkSession\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMd5(text):\n",
    "    return hashlib.md5(text.encode('utf-8')).hexdigest()\n",
    "md5Udf= udf(lambda z: createMd5(z),StringType())\n",
    "\n",
    "def clean_lower(text):\n",
    "    sentence = text.translate(str.maketrans('', '', '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^`{|}~-_”“«»‘')).lower()\n",
    "    return \" \".join(sentence.split())\n",
    "cleanLowerUdf= udf(lambda z: clean_lower(z),StringType())\n",
    "\n",
    "def get_site_from_url(text):\n",
    "    return text.split(\"/\")[2]\n",
    "getUrl= udf(lambda z: get_site_from_url(z),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_ip = socket.gethostbyname('minio')\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName(\"Python Spark S3\"). \\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName). \\\n",
    "    config(\"spark.executor.memory\", \"80g\"). \\\n",
    "    config(\"spark.driver.memory\", \"80g\"). \\\n",
    "    config('spark.dirver.maxResultSize', '5g'). \\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName). \\\n",
    "    config('spark.hadoop.fs.s3a.endpoint', 'http://'+minio_ip+':9000'). \\\n",
    "    config(\"spark.hadoop.fs.s3a.access.key\", \"minio-access-key\"). \\\n",
    "    config(\"spark.hadoop.fs.s3a.secret.key\", \"minio-secret-key\"). \\\n",
    "    config('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem'). \\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-python-adapter-3.0_2.12:1.0.0-incubating,org.datasyslab:geotools-wrapper:geotools-24.0'). \\\n",
    "    getOrCreate()\n",
    "SedonaRegistrator.registerAll(spark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
